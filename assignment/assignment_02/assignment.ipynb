{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment of Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import essential dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tkthanatorn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tkthanatorn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and clean dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_data() -> pd.DataFrame:\n",
    "    data = pd.read_csv(\"../../data/software_development_usa.csv\")\n",
    "    description = data[\"job_description\"]\n",
    "    cleaned_description = description.apply(\n",
    "        lambda s: s.translate(str.maketrans(\"\", \"\", string.punctuation + \"\\xa0\"))\n",
    "    )\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(\n",
    "        lambda s: s.translate(\n",
    "            str.maketrans(string.whitespace, \" \" * len(string.whitespace), \"\")\n",
    "        )\n",
    "    )\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       the chosen sr software developer will be part ...\n",
       "1       position c lead software developer location mi...\n",
       "2       senior software developer hoboken nj starts as...\n",
       "3       our client a multinational publishing and educ...\n",
       "4       position c lead software developer location ph...\n",
       "                              ...                        \n",
       "9991    position description  position description  cg...\n",
       "9994    job description  researches designs develops a...\n",
       "9997    job description  the candidate must be experie...\n",
       "9998    please only apply if you do not need sponsorsh...\n",
       "9999    company information  solid reputation passiona...\n",
       "Name: job_description, Length: 7583, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_description = get_and_clean_data()\n",
    "cleaned_description = cleaned_description\n",
    "cleaned_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and remove stop words from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [chosen, software, developer, part, larger, en...\n",
       "1       [position, lead, software, developer, location...\n",
       "2       [senior, software, developer, hoboken, starts,...\n",
       "3       [client, multinational, publishing, education,...\n",
       "4       [position, lead, software, developer, location...\n",
       "                              ...                        \n",
       "9991    [position, description, position, description,...\n",
       "9994    [job, description, researches, designs, develo...\n",
       "9997    [job, description, candidate, experienced, mic...\n",
       "9998    [apply, sponsorship, work, united, states, fut...\n",
       "9999    [company, information, solid, reputation, pass...\n",
       "Name: job_description, Length: 7583, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_description = cleaned_description.apply(lambda s: word_tokenize(s))\n",
    "stop_set = set(stopwords.words())\n",
    "\n",
    "sw_removed_description = tokenized_description.apply(\n",
    "    lambda s: [word for word in s if word not in stop_set]\n",
    ")\n",
    "\n",
    "sw_removed_description = sw_removed_description.apply(\n",
    "    lambda s: [word for word in s if len(word) > 2]\n",
    ")\n",
    "\n",
    "sw_removed_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemmed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [chosen, softwar, develop, part, larger, engin...\n",
       "1       [posit, lead, softwar, develop, locat, middlet...\n",
       "2       [senior, softwar, develop, hoboken, start, 912...\n",
       "3       [client, multin, publish, educ, compani, seek,...\n",
       "4       [posit, lead, softwar, develop, locat, philade...\n",
       "                              ...                        \n",
       "9991    [posit, descript, posit, descript, cgi, experi...\n",
       "9994    [job, descript, research, design, develop, and...\n",
       "9997    [job, descript, candid, experienc, microsoft, ...\n",
       "9998    [appli, sponsorship, work, unit, state, futur,...\n",
       "9999    [compani, inform, solid, reput, passion, endle...\n",
       "Name: job_description, Length: 7583, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_description = sw_removed_description.apply(lambda s: [ps.stem(w) for w in s])\n",
    "stemmed_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert a datasets to a matrix of token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7583x35944 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1296957 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(analyzer=lambda x: x)\n",
    "X = cv.fit_transform(stemmed_description)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benchmark performance of each metric in multitreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "XX = X.toarray()\n",
    "\n",
    "\n",
    "def timeit_matmul():\n",
    "    time = timeit.timeit(lambda: np.matmul(XX, XX.T), number=3) / 3\n",
    "    print(\"[{}] matmul(): {:.2f}\".format(\"FAST\" if time < 60 else \"TOO LONG\", time))\n",
    "    return \"matmul\", time\n",
    "\n",
    "\n",
    "def timeit_dok():\n",
    "    time = timeit.timeit(lambda: X.todok() * X.T.todok(), number=3) / 3\n",
    "    print(\"[{}] dok(): {:.2f}\".format(\"FAST\" if time < 60 else \"TOO LONG\", time))\n",
    "    return \"dok\", time\n",
    "\n",
    "\n",
    "def timeit_lil():\n",
    "    time = timeit.timeit(lambda: X.tolil() * X.T.tolil(), number=3) / 3\n",
    "    print(\"[{}] lil(): {:.2f}\".format(\"FAST\" if time < 60 else \"TOO LONG\", time))\n",
    "    return \"lil\", time\n",
    "\n",
    "\n",
    "def timeit_coo():\n",
    "    time = timeit.timeit(lambda: X.tocoo() * X.T.tocoo(), number=3) / 3\n",
    "    print(\"[{}] coo(): {:.2f}\".format(\"FAST\" if time < 60 else \"TOO LONG\", time))\n",
    "    return \"coo\", time\n",
    "\n",
    "\n",
    "def timeit_csc():\n",
    "    time = timeit.timeit(lambda: X.tocsc() * X.T.tocsc(), number=3) / 3\n",
    "    print(\"[{}] csc(): {:.2f}\".format(\"FAST\" if time < 60 else \"TOO LONG\", time))\n",
    "    return \"csc\", time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the result\n",
    "1. csc() -> 13.43 seconds\n",
    "2. coo() -> 13.44 seconds\n",
    "3. lil() -> 13.62 seconds\n",
    "4. dok() -> 16.37 seconds\n",
    "5. matmul() -> 1 hours 24 minutes **too long task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAST] csc(): 13.43\n",
      "[FAST] coo(): 13.44\n",
      "[FAST] lil(): 13.62\n",
      "[FAST] dok(): 16.37\n",
      "[TOO LONG] matmul(): 4457.03\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "with futures.ThreadPoolExecutor(max_workers=5) as thread:\n",
    "    thread.submit(timeit_matmul)\n",
    "    thread.submit(timeit_dok)\n",
    "    thread.submit(timeit_lil)\n",
    "    thread.submit(timeit_coo)\n",
    "    thread.submit(timeit_csc)\n",
    "    thread.shutdown(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
