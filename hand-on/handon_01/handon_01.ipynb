{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Import dependencies for Hand-on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read and clean `software_development_usa.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_data() -> pd.DataFrame:\n",
    "    data = pd.read_csv(\"../../data/software_development_usa.csv\")\n",
    "    description = data[\"job_description\"]\n",
    "    cleaned_description = description.apply(\n",
    "        lambda s: s.translate(str.maketrans(\"\", \"\", string.punctuation + \"\\xa0\"))\n",
    "    )\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(\n",
    "        lambda s: s.translate(\n",
    "            str.maketrans(string.whitespace, \" \" * len(string.whitespace), \"\")\n",
    "        )\n",
    "    )\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the chosen sr software developer will be part ...\n",
       "1    position c lead software developer location mi...\n",
       "2    senior software developer hoboken nj starts as...\n",
       "3    our client a multinational publishing and educ...\n",
       "4    position c lead software developer location ph...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_and_clean_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tokenize the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cleaned_description = data.apply(lambda s: [x.strip() for x in s.split()])\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [the, chosen, sr, software, developer, will, b...\n",
       "1    [position, c, lead, software, developer, locat...\n",
       "2    [senior, software, developer, hoboken, nj, sta...\n",
       "3    [our, client, a, multinational, publishing, an...\n",
       "4    [position, c, lead, software, developer, locat...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = simple_tokenize(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Combine `get_and_clean_data()` and `simple_tokenize()` into `parse_job_description()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job_description():\n",
    "    cleaned_description = get_and_clean_data()\n",
    "    cleaned_description = simple_tokenize(cleaned_description)\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Count `Python + MySQL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 1379 of 7583\n",
      "mysql: 667 of 7583\n"
     ]
    }
   ],
   "source": [
    "def count_python_mysql():\n",
    "    parsed_description = parse_job_description()\n",
    "    count_python = parsed_description.apply(lambda s: \"python\" in s).sum()\n",
    "    count_mysql = parsed_description.apply(lambda s: \"mysql\" in s).sum()\n",
    "    print(\"python: \" + str(count_python) + \" of \" + str(parsed_description.shape[0]))\n",
    "    print(\"mysql: \" + str(count_mysql) + \" of \" + str(parsed_description.shape[0]))\n",
    "\n",
    "\n",
    "count_python_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_db() -> list[list[str]]:\n",
    "    html_doc = requests.get(\"https://db-engines.com/en/ranking\").content\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "    db_table = soup.find(\"table\", {\"class\": \"dbi\"})\n",
    "    all_db = [\n",
    "        \"\".join(s.find(\"a\").findAll(text=True, recursive=True)).strip()\n",
    "        for s in db_table.findAll(\"th\", {\"class\": \"pad-l\"})\n",
    "    ]\n",
    "    all_db = list(dict.fromkeys(all_db))\n",
    "    db_list = all_db[:10]\n",
    "    db_list = [s.lower() for s in db_list]\n",
    "    db_list = [[[x.strip() for x in s.split()][0]] for s in db_list]\n",
    "    return db_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66464/4149286022.py:6: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  \"\".join(s.find(\"a\").findAll(text=True, recursive=True)).strip()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['oracle'],\n",
       " ['mysql'],\n",
       " ['microsoft'],\n",
       " ['postgresql'],\n",
       " ['mongodb'],\n",
       " ['redis'],\n",
       " ['elasticsearch'],\n",
       " ['ibm'],\n",
       " ['sqlite'],\n",
       " ['microsoft']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How many database is in description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66464/4149286022.py:6: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  \"\".join(s.find(\"a\").findAll(text=True, recursive=True)).strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle: 1392 of 7583\n",
      "mysql: 667 of 7583\n",
      "microsoft: 1516 of 7583\n",
      "postgresql: 261 of 7583\n",
      "mongodb: 296 of 7583\n",
      "redis: 106 of 7583\n",
      "elasticsearch: 161 of 7583\n",
      "ibm: 227 of 7583\n",
      "sqlite: 28 of 7583\n",
      "microsoft: 1516 of 7583\n"
     ]
    }
   ],
   "source": [
    "cleaned_db = parse_db()\n",
    "parsed_description = parse_job_description()\n",
    "raw = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    raw[i] = parsed_description.apply(lambda s: np.all([x in s for x in db])).sum()\n",
    "    print(\" \".join(db) + \": \" + str(raw[i]) + \" of \" + str(parsed_description.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How many of each database that alongside python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle + python: 243 of 7583\n",
      "mysql + python: 207 of 7583\n",
      "microsoft + python: 138 of 7583\n",
      "postgresql + python: 90 of 7583\n",
      "mongodb + python: 111 of 7583\n",
      "redis + python: 38 of 7583\n",
      "elasticsearch + python: 73 of 7583\n",
      "ibm + python: 63 of 7583\n",
      "sqlite + python: 7 of 7583\n",
      "microsoft + python: 138 of 7583\n"
     ]
    }
   ],
   "source": [
    "with_oracle: list[pd.DataFrame] = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    with_oracle[i] = parsed_description.apply(\n",
    "        lambda s: np.all([x in s for x in db]) and \"python\" in s\n",
    "    ).sum()\n",
    "\n",
    "    print(\n",
    "        \" \".join(db)\n",
    "        + \" + python: \"\n",
    "        + str(with_oracle[i])\n",
    "        + \" of \"\n",
    "        + str(parsed_description.shape[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle + python 243 of 1392 (17.46%)\n",
      "mysql + python 207 of 667 (31.03%)\n",
      "microsoft + python 138 of 1516 (9.1%)\n",
      "postgresql + python 90 of 261 (34.48%)\n",
      "mongodb + python 111 of 296 (37.5%)\n",
      "redis + python 38 of 106 (35.85%)\n",
      "elasticsearch + python 73 of 161 (45.34%)\n",
      "ibm + python 63 of 227 (27.75%)\n",
      "sqlite + python 7 of 28 (25.0%)\n",
      "microsoft + python 138 of 1516 (9.1%)\n"
     ]
    }
   ],
   "source": [
    "for i, db in enumerate(cleaned_db):\n",
    "    print(\n",
    "        \" \".join(db)\n",
    "        + \" + python \"\n",
    "        + str(with_oracle[i])\n",
    "        + \" of \"\n",
    "        + str(raw[i])\n",
    "        + \" (\"\n",
    "        + str(np.around(with_oracle[i] / raw[i] * 100, 2))\n",
    "        + \"%)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66464/4149286022.py:6: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  \"\".join(s.find(\"a\").findAll(text=True, recursive=True)).strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>java</th>\n",
       "      <th>python</th>\n",
       "      <th>c</th>\n",
       "      <th>kotlin</th>\n",
       "      <th>swift</th>\n",
       "      <th>rust</th>\n",
       "      <th>ruby</th>\n",
       "      <th>scala</th>\n",
       "      <th>julia</th>\n",
       "      <th>lua</th>\n",
       "      <th>oracle</th>\n",
       "      <th>mysql</th>\n",
       "      <th>microsoft</th>\n",
       "      <th>postgresql</th>\n",
       "      <th>mongodb</th>\n",
       "      <th>redis</th>\n",
       "      <th>elasticsearch</th>\n",
       "      <th>ibm</th>\n",
       "      <th>sqlite</th>\n",
       "      <th>microsoft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7583 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      java  python  c  kotlin  swift  rust  ruby  scala  julia  lua  oracle  \\\n",
       "0        0       0  1       0      0     0     0      0      0    0       0   \n",
       "1        0       0  1       0      0     0     0      0      0    0       0   \n",
       "2        0       0  0       0      0     0     0      0      0    0       0   \n",
       "3        0       0  0       0      0     0     0      0      0    0       0   \n",
       "4        0       0  1       0      0     0     0      0      0    0       0   \n",
       "...    ...     ... ..     ...    ...   ...   ...    ...    ...  ...     ...   \n",
       "7578     1       1  0       0      0     0     0      0      0    0       1   \n",
       "7579     1       0  0       0      0     0     0      0      0    0       1   \n",
       "7580     0       0  1       0      0     0     0      0      0    0       0   \n",
       "7581     1       0  0       0      0     0     0      0      0    0       1   \n",
       "7582     1       0  0       0      0     0     0      0      0    0       0   \n",
       "\n",
       "      mysql  microsoft  postgresql  mongodb  redis  elasticsearch  ibm  \\\n",
       "0         0          0           1        0      0              0    0   \n",
       "1         0          1           0        0      0              0    0   \n",
       "2         0          0           0        0      0              0    0   \n",
       "3         0          0           0        0      0              0    0   \n",
       "4         0          1           0        0      0              0    0   \n",
       "...     ...        ...         ...      ...    ...            ...  ...   \n",
       "7578      1          0           0        0      0              0    1   \n",
       "7579      0          0           0        0      0              0    0   \n",
       "7580      0          1           0        0      0              0    0   \n",
       "7581      1          0           0        0      0              0    0   \n",
       "7582      0          0           0        1      0              0    0   \n",
       "\n",
       "      sqlite  microsoft  \n",
       "0          0          0  \n",
       "1          0          1  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          0          1  \n",
       "...      ...        ...  \n",
       "7578       0          0  \n",
       "7579       0          0  \n",
       "7580       0          1  \n",
       "7581       0          0  \n",
       "7582       0          0  \n",
       "\n",
       "[7583 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = [\n",
    "    [\"java\"],\n",
    "    [\"python\"],\n",
    "    [\"c\"],\n",
    "    [\"kotlin\"],\n",
    "    [\"swift\"],\n",
    "    [\"rust\"],\n",
    "    [\"ruby\"],\n",
    "    [\"scala\"],\n",
    "    [\"julia\"],\n",
    "    [\"lua\"],\n",
    "]\n",
    "parsed_description = parse_job_description()\n",
    "parsed_db = parse_db()\n",
    "all_terms = langs + parsed_db\n",
    "query_map = pd.DataFrame(\n",
    "    parsed_description.apply(\n",
    "        lambda s: [1 if np.all([d in s for d in db]) else 0 for db in all_terms]\n",
    "    ).values.tolist(),\n",
    "    columns=[\" \".join(d) for d in all_terms],\n",
    ")\n",
    "query_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "1. What DB should I learn after java?\n",
    "2. Which DB is in demand alongside oracle?\n",
    "3. What programming language is in demand alongside python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What DB should I learn after Java?\n",
    "Oracle is the database that you should learn after Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle + java: 913 of 7583\n",
      "mysql + java: 397 of 7583\n",
      "microsoft + java: 448 of 7583\n",
      "postgresql + java: 161 of 7583\n",
      "mongodb + java: 166 of 7583\n",
      "redis + java: 40 of 7583\n",
      "elasticsearch + java: 112 of 7583\n",
      "ibm + java: 135 of 7583\n",
      "sqlite + java: 5 of 7583\n",
      "microsoft + java: 448 of 7583\n"
     ]
    }
   ],
   "source": [
    "with_oracle: list[pd.DataFrame] = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    with_oracle[i] = parsed_description.apply(\n",
    "        lambda s: np.all([x in s for x in db]) and \"java\" in s\n",
    "    ).sum()\n",
    "\n",
    "    print(\n",
    "        \" \".join(db)\n",
    "        + \" + java: \"\n",
    "        + str(with_oracle[i])\n",
    "        + \" of \"\n",
    "        + str(parsed_description.shape[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which DB is in demand alongside oracle?\n",
    "MySQL is the DB that you should learn alongside oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql + oracle: 312 of 7583\n",
      "microsoft + oracle: 282 of 7583\n",
      "postgresql + oracle: 100 of 7583\n",
      "mongodb + oracle: 104 of 7583\n",
      "redis + oracle: 12 of 7583\n",
      "elasticsearch + oracle: 32 of 7583\n",
      "ibm + oracle: 84 of 7583\n",
      "sqlite + oracle: 17 of 7583\n",
      "microsoft + oracle: 282 of 7583\n"
     ]
    }
   ],
   "source": [
    "with_oracle: list[pd.DataFrame] = [None] * len(cleaned_db)\n",
    "for i, db in enumerate(cleaned_db):\n",
    "    if db[0] == \"oracle\":\n",
    "        continue\n",
    "\n",
    "    with_oracle[i] = parsed_description.apply(\n",
    "        lambda s: np.all([x in s for x in db]) and \"oracle\" in s\n",
    "    ).sum()\n",
    "\n",
    "    print(\n",
    "        \" \".join(db)\n",
    "        + \" + oracle: \"\n",
    "        + str(with_oracle[i])\n",
    "        + \" of \"\n",
    "        + str(parsed_description.shape[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What programming language is in demand alongside python?\n",
    "Java is the programming language is in demand alongside python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java + python: 830 of 7583\n",
      "c + python: 689 of 7583\n",
      "kotlin + python: 6 of 7583\n",
      "swift + python: 37 of 7583\n",
      "rust + python: 6 of 7583\n",
      "ruby + python: 181 of 7583\n",
      "scala + python: 76 of 7583\n",
      "julia + python: 1 of 7583\n",
      "lua + python: 11 of 7583\n"
     ]
    }
   ],
   "source": [
    "with_python: list[pd.DataFrame] = [None] * len(langs)\n",
    "for i, db in enumerate(langs):\n",
    "    if db[0] == \"python\":\n",
    "        continue\n",
    "\n",
    "    with_oracle[i] = parsed_description.apply(\n",
    "        lambda s: np.all([x in s for x in db]) and \"python\" in s\n",
    "    ).sum()\n",
    "\n",
    "    print(\n",
    "        \" \".join(db)\n",
    "        + \" + python: \"\n",
    "        + str(with_oracle[i])\n",
    "        + \" of \"\n",
    "        + str(parsed_description.shape[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"the chosen software developer will be part of a larger engineering team developing software for medical devices.\"\n",
    "\n",
    "str2 = \"we are seeking a seasoned software developer with strong analytical and technical skills to join our public sector technology consulting team.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkthanatorn/miniconda3/envs/quant/lib/python3.11/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tkthanatorn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tkthanatorn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analyt', 'chosen', 'consult', 'develop', 'develop', 'devic',\n",
       "       'engin', 'join', 'larger', 'medic', 'part', 'public', 'season',\n",
       "       'sector', 'seek', 'skill', 'softwar', 'softwar', 'strong', 'team',\n",
       "       'team', 'technic', 'technolog'], dtype='<U9')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_string(data: str):\n",
    "    tokened = word_tokenize(data)\n",
    "    tokened = [w for w in tokened if len(w) > 2]\n",
    "    clean_stopword = [word for word in tokened if not word in stopwords.words()]\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    stemmed = np.unique([ps.stem(w) for w in clean_stopword])\n",
    "    return stemmed\n",
    "\n",
    "prepared1 = prepare_string(str1)\n",
    "prepared2 = prepare_string(str2)\n",
    "full_list = np.sort(np.concatenate([prepared1, prepared2]))\n",
    "full_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
